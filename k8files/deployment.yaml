apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: spark-submit
  labels:
    name: spark-submit
    namespace: default
spec:
  replicas: 1
  selector:
    matchLabels:
      name: spark-submit
  strategy:
    type: Recreate
  template:
    metadata:
      labels:
        name: spark-submit
        type: dedicated
    spec:
      nodeSelector:
        nodeNamespace: default
      affinity:
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchExpressions:
              - key: type
                operator: In
                values:
                - dedicated
            topologyKey: kubernetes.io/hostname
      containers:
      - name: spark-submit
        image: icpauloledo/spark-submit:v0.1
        resources:
          requests:
            cpu: 1000m
          limits:
            cpu: 2000m
        env:
          - name: IMAGE_TAG
            value: latest
          - name: PROJECT_NAME
            value: batch-processor
          - name: CLASS_NAME
            value: .batch.BatchProcessor
          - name: TAG_VERSION
            value: "0.1"
          - name: K8S_MASTER
            value: k8s://https://api.k8s.my-cluster:443
          - name: APP_NAME
            value: batch-processor
          - name: IMAGE_URL
            value: my-registrys/analytics-batch-processor
          - name: DB_URL
            value: jdbc:postgresql://my-db:5432/datalake
          - name: DB_USERNAME
            value: my-db-user
          - name: DB_PASSWORD
            value: my-db-pass
          - name: DB2_URL
            value: jdbc:postgresql://my-db2:5432/db2-db
          - name: DB2_USERNAME
            value: my-db2-user
          - name: DB2_PASSWORD
            value: my-db2-pass
          - name: SPARK_EXECUTOR_INSTANCES
            value: "1"
          - name: SPARK_K8S_DRIVER_CORE_LIMIT
            value: "1000m"
          - name: SPARK_K8S_EXECUTOR_LIMIT_CORES
            value: "1000m"
          - name: SPARK_K8S_EXECUTOR_REQUEST_CORES
            value: "1000m"
        command: ["spark-submit"]
        args:
        -  --master=$(K8S_MASTER)
        -  --deploy-mode=cluster 
        -  --name=$(APP_NAME)
        -  --class=$(CLASS_NAME)
        -  --conf=spark.executor.instances=$(SPARK_EXECUTOR_INSTANCES)
        -  --conf=spark.kubernetes.driver.limit.cores=$(SPARK_K8S_DRIVER_CORE_LIMIT)
        -  --conf=spark.kubernetes.executor.request.cores=$(SPARK_K8S_EXECUTOR_REQUEST_CORES)
        -  --conf=spark.kubernetes.executor.limit.cores=$(SPARK_K8S_EXECUTOR_LIMIT_CORES)
        -  --conf=spark.kubernetes.container.image=$(IMAGE_URL):$(IMAGE_TAG)
        -  --conf=spark.kubernetes.driverEnv.ANALYTIC_URL=$(DB_URL)
        -  --conf=spark.kubernetes.driverEnv.ANALYTIC_USERNAME=$(DB_USERNAME)
        -  --conf=spark.kubernetes.driverEnv.ANALYTIC_PASSWORD=$(DB_PASSWORD)
        -  --conf=spark.kubernetes.driverEnv.LANDING_URL=$(DB2_URL)
        -  --conf=spark.kubernetes.driverEnv.LANDING_USERNAME=$(DB2_USERNAME)
        -  --conf=spark.kubernetes.driverEnv.LANDING_PASSWORD=$(DB2_PASSWORD)
        -  --conf=spark.kubernetes.authenticate.driver.serviceAccountName=spark-submit  <<<<< here you should put your serviceAccount
        -  --executor-memory=2G
        -  --driver-memory=2G
        -  local:///$(PROJECT_NAME)/target/scala-2.11/$(PROJECT_NAME)-assembly-$(TAG_VERSION).jar

