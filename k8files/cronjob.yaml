apiVersion: batch/v1beta1
kind: CronJob
metadata:
  labels:
    name: spark-submit-1
  name: spark-submit-1
  namespace: default
spec:
  concurrencyPolicy: Replace
  failedJobsHistoryLimit: 1
  jobTemplate:
    metadata:
      creationTimestamp: null
    spec:
      activeDeadlineSeconds: 900
      template:
        metadata:
          creationTimestamp: null
        spec:

          containers:
          - name: spark-submit-1
            image: icpauloledo/spark-submit:v0.1
            imagePullPolicy: Always
            name: spark-submit-1

            env:
              - name: EXECUTOR_MEMORY
                value: 1G
              - name: DRIVER_MEMORY
                value: 1G
              - name: SPARK_IMAGE
                value: icpauloledo/spark:v0.1
              - name: K8_SERVICE_ACCOUNT
                value: spark-submit
              - name: CLASS_NAME
                value: org.apache.spark.examples.SparkPi
              - name: K8S_MASTER
                value: k8s://https://api.k8s.stage.elinvar.tech:443
              - name: APP_NAME
                value: spark-pi
              - name: AP_ARTIFACT
                value: opt/spark/examples/jars/spark-examples_2.11-2.4.0.jar
              - name: SPARK_EXECUTOR_INSTANCES
                value: "1"
              - name: SPARK_K8S_DRIVER_CORE_LIMIT
                value: "1000m"
              - name: SPARK_K8S_EXECUTOR_LIMIT_CORES
                value: "1000m"
              - name: SPARK_K8S_EXECUTOR_REQUEST_CORES
                value: "1000m"

            command: ["spark-submit"]
            args:
            -  --master=$(K8S_MASTER)
            -  --deploy-mode=cluster
            -  --name=$(APP_NAME)
            -  --class=$(CLASS_NAME)
            -  --conf=spark.executor.instances=$(SPARK_EXECUTOR_INSTANCES)
            -  --conf=spark.kubernetes.driver.limit.cores=$(SPARK_K8S_DRIVER_CORE_LIMIT)
            -  --conf=spark.kubernetes.executor.request.cores=$(SPARK_K8S_EXECUTOR_REQUEST_CORES)
            -  --conf=spark.kubernetes.executor.limit.cores=$(SPARK_K8S_EXECUTOR_LIMIT_CORES)
            -  --conf=spark.kubernetes.container.image=$(SPARK_IMAGE)
            -  --conf=spark.kubernetes.authenticate.driver.serviceAccountName=$(K8_SERVICE_ACCOUNT)
            -  --executor-memory=$(EXECUTOR_MEMORY)
            -  --driver-memory=$(DRIVER_MEMORY)
            -  local:///$(AP_ARTIFACT)

            resources:
              limits:
                cpu: 1000m
              requests:
                cpu: 1000m

            terminationMessagePath: /dev/termination-log
            terminationMessagePolicy: File

          dnsPolicy: ClusterFirst
          nodeSelector:
            nodeNamespace: default
          restartPolicy: Never
          schedulerName: default-scheduler
          securityContext: {}
          terminationGracePeriodSeconds: 30

  schedule: 15 13 * * *
  successfulJobsHistoryLimit: 0
  suspend: false
